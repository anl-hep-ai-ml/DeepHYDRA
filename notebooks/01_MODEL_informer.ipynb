{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa2afc2",
   "metadata": {},
   "source": [
    "# Looking at the Informer model \n",
    "\n",
    "In what follows we look at the informer model, it's parts and the general idea. <br>\n",
    "\n",
    "The Informer model, was designed for efficient and effective long-sequence time-series forecasting. <br>\n",
    "Improving the usual Transformer architectures to handle long sequences more efficiently.<br>\n",
    "\n",
    "This model identify deviations in patterns over time by forecasting expected values and comparing them to actual observations. <br>\n",
    "\n",
    "\n",
    "Consists of:\n",
    "\n",
    " -   **Encoder**: Processes the input time series data to capture temporal dependencies.\n",
    " -   **Decoder**: Generates future time steps based on the encoded information.\n",
    " -   **ProbSparse Self-Attention Mechanism**: Efficiently handles long sequences by selecting only the most relevant attention scores.\n",
    " -   **Embedding Layers**: Convert raw input data and temporal features into a format suitable for the model.\n",
    " \n",
    " \n",
    "By forecasting future time steps and comparing them with actual observations, anomalies can be detected when there is a significant deviation.<br>\n",
    "Temporal Features: Embedding temporal features helps the model understand and anticipate regular patterns, making it easier to spot irregularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9ed7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b800972",
   "metadata": {},
   "source": [
    "## 1. Informer Class\n",
    "\n",
    "Check **model.py**\n",
    "\n",
    "This is the main class that brings together the encoder, decoder, and embedding layers.\n",
    "\n",
    "Components:\n",
    "\n",
    " -    Encoding: Prepares input data for the encoder.\n",
    " -    Encoder: Processes input sequences.\n",
    " -    Decoder: Generates output sequences.\n",
    " -    Projection Layer: Maps the decoder output to the output dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe48c4",
   "metadata": {},
   "source": [
    "```python\n",
    "class Informer(nn.Module):\n",
    "    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n",
    "                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n",
    "                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n",
    "                output_attention = False, distil=True, mix=True,\n",
    "                device=torch.device('cuda:0')):\n",
    "        ...\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, ...):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cc923",
   "metadata": {},
   "source": [
    "As all the following classes, it inherits from **nn.Module**, making it a PyTorch neural network module.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- enc_in: Number of input features for the encoder.\n",
    "- dec_in: Number of input features for the decoder.\n",
    "- c_out: Number of output features (usually equal to dec_in).\n",
    "- seq_len: Length of the input sequence to the encoder.\n",
    "- label_len: Length of the known output sequence (used as input to the decoder).\n",
    "- out_len: Length of the output sequence to predict.\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "- factor: Controls the sparsity in ProbSparse attention.\n",
    "- d_model: Dimension of the model (embedding size).\n",
    "- n_heads: Number of attention heads.\n",
    "- e_layers: Number of encoder layers.\n",
    "- d_layers: Number of decoder layers.\n",
    "- d_ff: Dimension of the feed-forward networks (usually 4 times d_model).\n",
    "- dropout: Dropout rate for regularization.\n",
    "- attn: Type of attention mechanism ('prob' for ProbSparse, 'full' for full attention).\n",
    "- embed: Type of embedding ('fixed' or 'timeF').\n",
    "- freq: Granularity of time features ('h' for hourly, etc.).\n",
    "- activation: Activation function used in feed-forward networks.\n",
    "- output_attention: Whether to output attention weights (useful for visualization).\n",
    "- distil: Whether to use distilling in the encoder (using convolutional layers to reduce sequence length).\n",
    "- mix: Whether to use mix attention in the decoder.\n",
    "- device: The device on which to run the model (CPU or GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fdba2",
   "metadata": {},
   "source": [
    "## Components Initialization\n",
    "\n",
    "### a. Embedding Layers\n",
    "\n",
    "```python\n",
    "self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "```\n",
    "\n",
    "Convert raw input data (x_enc, x_dec) and their corresponding time features (x_mark_enc, x_mark_dec) into embeddings.\n",
    "\n",
    "- Value Embedding: Embeds the raw time series values.\n",
    "- Position Embedding: Adds positional information to the embeddings.\n",
    "- Temporal Embedding: Adds time-related features to the embeddings.\n",
    "\n",
    "### b. Attention Mechanism Selection\n",
    "\n",
    "```python\n",
    "Attn = ProbAttention if attn == 'prob' else FullAttention\n",
    "```\n",
    "\n",
    "Chooses the attention mechanism based on the attn parameter.\n",
    "- ProbAttention: Efficient attention mechanism for long sequences.\n",
    "- FullAttention: Standard attention mechanism.\n",
    "\n",
    "### c. Encoder Initialization\n",
    "\n",
    "```python\n",
    "self.encoder = Encoder(\n",
    "    [\n",
    "        EncoderLayer(\n",
    "            AttentionLayer(\n",
    "                Attn(False, factor, attention_dropout=dropout, output_attention=output_attention),\n",
    "                d_model, n_heads, mix=False\n",
    "            ),\n",
    "            d_model,\n",
    "            d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=activation\n",
    "        ) for l in range(e_layers)\n",
    "    ],\n",
    "    [\n",
    "        ConvLayer(d_model) for l in range(e_layers - 1)\n",
    "    ] if distil else None,\n",
    "    norm_layer=torch.nn.LayerNorm(d_model)\n",
    ")\n",
    "```\n",
    "\n",
    "- Encoder Layers: A list of EncoderLayer instances.\n",
    "- Convolutional Layers (ConvLayer): Optional layers for downsampling (used if distil is True).\n",
    "- Normalization Layer: Applies layer normalization after the encoder stack.\n",
    "\n",
    "\n",
    "Details:\n",
    "- AttentionLayer: Applies self-attention.\n",
    "  - Attn: The chosen attention mechanism (ProbAttention or FullAttention).\n",
    "  - Parameters:\n",
    "    - mask_flag: Indicates whether to apply attention masking.\n",
    "    - factor: Controls sparsity in ProbAttention.\n",
    "    - attention_dropout: Dropout rate in the attention mechanism.\n",
    "    - output_attention: Whether to output attention weights.\n",
    "    \n",
    "- Feed-Forward Network (FFN):\n",
    "  - Conv1d Layers: Two convolutional layers acting as position-wise FFN.\n",
    "  - Activation Function: Specified by *activation* parameter (e.g., ReLU, GELU).\n",
    "  \n",
    "- Layer Normalization and Dropout: Applied after attention and FFN.\n",
    "\n",
    "\n",
    "\n",
    "### d. Decoder Initialization\n",
    "\n",
    "```python\n",
    "self.decoder = Decoder(\n",
    "    [\n",
    "        DecoderLayer(\n",
    "            AttentionLayer(\n",
    "                Attn(True, factor, attention_dropout=dropout, output_attention=False),\n",
    "                d_model, n_heads, mix=mix\n",
    "            ),\n",
    "            AttentionLayer(\n",
    "                FullAttention(False, factor, attention_dropout=dropout, output_attention=False),\n",
    "                d_model, n_heads, mix=False\n",
    "            ),\n",
    "            d_model,\n",
    "            d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "        )\n",
    "        for l in range(d_layers)\n",
    "    ],\n",
    "    norm_layer=torch.nn.LayerNorm(d_model)\n",
    ")\n",
    "```\n",
    "\n",
    "- Decoder Layers: A list of DecoderLayer instances.\n",
    "- Normalization Layer: Applies layer normalization after the decoder stack.\n",
    "\n",
    "\n",
    "Details:\n",
    "- Self-Attention Layer: Processes decoder inputs.\n",
    "    - Attn: The chosen attention mechanism, with mask_flag=True to prevent attending to future positions.\n",
    "\n",
    "- Cross-Attention Layer: Attends over the encoder outputs.\n",
    "    - FullAttention: Always uses full attention for cross-attention.\n",
    "- Feed-Forward Network (FFN): Similar to the encoder's FFN.\n",
    "- Layer Normalization and Dropout: Applied after each sub-layer.\n",
    "\n",
    "\n",
    "\n",
    "### e. Projection Layer\n",
    "\n",
    "```python\n",
    "self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "```\n",
    "\n",
    "Maps the output of the decoder to the desired output dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517324d",
   "metadata": {},
   "source": [
    "## Forward Method\n",
    "\n",
    "```python\n",
    "def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, ...):\n",
    "    ...\n",
    "```\n",
    "\n",
    "This method defines how data flows through the model.\n",
    "\n",
    "**Inputs**\n",
    " -   x_enc: Input sequence to the encoder (shape: [batch_size, seq_len, enc_in]).\n",
    " -   x_mark_enc: Time features corresponding to x_enc (shape: [batch_size, seq_len, num_time_features]).\n",
    " -   x_dec: Input sequence to the decoder (shape: [batch_size, out_len, dec_in]).\n",
    " -   x_mark_dec: Time features corresponding to x_dec (shape: [batch_size, out_len, num_time_features]).\n",
    " -   enc_self_mask, dec_self_mask, dec_enc_mask: Optional attention masks.\n",
    " -   viz_data: Optional data for visualization (not used now).\n",
    "\n",
    "**Steps**\n",
    "\n",
    "#### a. Embedding\n",
    "\n",
    "```python\n",
    "enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "```\n",
    "\n",
    "Convert raw inputs and time features into embeddings.\n",
    " - Value Embedding: Embed the input values.\n",
    " - Position Embedding: Add positional information.\n",
    " - Temporal Embedding: Embed time features.\n",
    " - Dropout: Apply dropout to prevent overfitting.\n",
    " \n",
    " \n",
    " \n",
    "#### b. Encoding\n",
    "\n",
    "```python\n",
    "enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "```\n",
    "\n",
    "Process the encoder embeddings to capture temporal dependencies.\n",
    "\n",
    " - Encoder Layers: Each layer applies self-attention and feed-forward network.\n",
    " - Optional Convolutional Layers: Reduce sequence length and capture local dependencies (if distil is True).\n",
    " - Attention Masks: Can be applied to prevent attention to certain positions.\n",
    " \n",
    " \n",
    "#### c. Decoding\n",
    "\n",
    "```python\n",
    "dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "```\n",
    "\n",
    "Generate predictions by attending over encoder outputs and decoder inputs.\n",
    "\n",
    " - Self-Attention in Decoder: Processes the decoder inputs, using causal masking to prevent access to future positions.\n",
    " - Cross-Attention: Allows the decoder to attend to encoder outputs.\n",
    " - Feed-Forward Network: Further processes the combined information.\n",
    " \n",
    " \n",
    "#### d. Projection\n",
    "\n",
    "```python\n",
    "dec_out = self.projection(dec_out)\n",
    "```\n",
    "\n",
    "Map the decoder output to the desired output dimension (*c_out*).\n",
    "\n",
    "\n",
    " \n",
    "#### e. Output\n",
    "\n",
    "```python\n",
    "if self.output_attention:\n",
    "    return dec_out[:, -self.pred_len:, :], attns\n",
    "else:\n",
    "    return dec_out[:, -self.pred_len:, :]\n",
    "```\n",
    "\n",
    "Return the final predictions (and optionally attention weights).\n",
    "\n",
    "- dec_out[:, -self.pred_len:, :]: Extracts the last pred_len time steps from the decoder output.\n",
    "- attns: If output_attention is True, returns attention weights for analysis or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edd71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6fbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5db2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c346a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5273aff8",
   "metadata": {},
   "source": [
    "## 2. Attention is all you need\n",
    "\n",
    "https://arxiv.org/pdf/1706.03762\n",
    "\n",
    "Classes defined in **attn.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05097cfd",
   "metadata": {},
   "source": [
    "### Full Attention\n",
    "\n",
    "\n",
    "Implements the standard full self-attention mechanism.<br>\n",
    "Is used when we set the attention mechanism to *'full'*.\n",
    "\n",
    "\n",
    " - Computes attention scores for all pairs of input positions.\n",
    " - Can be computationally intensive for long sequences.\n",
    " \n",
    "```python\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        ...\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153a7c7",
   "metadata": {},
   "source": [
    "### ProbAttention\n",
    "\n",
    "\n",
    "Implements the ProbSparse self-attention mechanism.\n",
    "The default attention mechanism in the Informer model.\n",
    "\n",
    "- Uses probability sampling to select the most relevant queries and keys.\n",
    "- Reduces computational complexity from $O(L^2)$ to $O(L\\text{ }log⁡L)$, where $L$ is the sequence length.\n",
    " \n",
    "```python\n",
    "class ProbAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        ...\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ba014",
   "metadata": {},
   "source": [
    "## 3. AttentionLayer\n",
    "\n",
    "Wraps around the attention mechanisms.\n",
    "\n",
    "- Projects input embeddings into queries, keys, and values.\n",
    "- Applies the attention mechanism.\n",
    "- Mixes the output if specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebab70",
   "metadata": {},
   "source": [
    "```python\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None, d_values=None, mix=False):\n",
    "        ...\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e7f24",
   "metadata": {},
   "source": [
    "## 4. Encoder and EncoderLayer\n",
    "\n",
    "Check **encoder.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911368b",
   "metadata": {},
   "source": [
    "### EncoderLayer\n",
    "\n",
    "A single layer within the encoder stack.\n",
    "\n",
    "- **Self-Attention**: Captures dependencies within the input sequence.\n",
    "- **Position-wise Feed-Forward Network (FFN)**: Processes the output of the attention layer.\n",
    "- **Layer Normalization and Dropout**: Stabilizes training and prevents overfitting.\n",
    "\n",
    "```python\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        ...\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66d13d",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Stacks multiple EncoderLayer instances.\n",
    "\n",
    "- Can include convolutional layers (ConvLayer) for downsampling and capturing local dependencies.\n",
    "- Applies normalization at the end.\n",
    "\n",
    "```python\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        ...\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf686890",
   "metadata": {},
   "source": [
    "### ConvLayer\n",
    "\n",
    "Applies convolutional operations to capture local temporal features.\n",
    "\n",
    "- Downsamples the sequence length.\n",
    "- Uses circular padding to handle sequence borders.\n",
    "\n",
    "```python\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        ...\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8ff81",
   "metadata": {},
   "source": [
    "## 5. Decoder and DecoderLayer\n",
    "\n",
    "Check **decoder.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee251eee",
   "metadata": {},
   "source": [
    "### DecoderLayer\n",
    "\n",
    "A single layer within the decoder stack.\n",
    "\n",
    "- **Self-Attention**: Processes the decoder input.\n",
    "- **Cross-Attention**: Attends over the encoder output.\n",
    "- **Feed-Forward Network**: Further processes the combined information.\n",
    "- **Layer Normalization and Dropout**.\n",
    "\n",
    "```python\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        ...\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f96584",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Stacks multiple *DecoderLayer* instances.\n",
    "\n",
    "- Processes the decoder inputs and the encoder outputs to generate predictions.\n",
    "- Applies normalization at the end.\n",
    "\n",
    "```python\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None):\n",
    "        ...\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6c64a",
   "metadata": {},
   "source": [
    "## 6. Embedding Layers\n",
    "\n",
    "Check **embed.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88c433",
   "metadata": {},
   "source": [
    "### DataEmbedding\n",
    "\n",
    "Converts raw input data into embeddings suitable for the model.\n",
    "\n",
    "- **Value Embedding (TokenEmbedding)**: Embeds the input time series values.\n",
    "- **Position Embedding (PositionalEmbedding)**: Adds positional information to the embeddings.\n",
    "- **Temporal Embedding (TemporalEmbedding or TimeFeatureEmbedding)**: Encodes temporal features like time of day, day of the week, etc.\n",
    "- **Dropout**: Prevents overfitting.\n",
    "\n",
    "```python\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        ...\n",
    "    def forward(self, x, x_mark):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07897a0d",
   "metadata": {},
   "source": [
    "### TokenEmbedding\n",
    "\n",
    "Applies a convolution to embed input values.\n",
    "\n",
    "- Uses a 1D convolution to capture local patterns in the input data.\n",
    "\n",
    "```python\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        ...\n",
    "    def forward(self, x):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444dfe64",
   "metadata": {},
   "source": [
    "### PositionalEmbedding\n",
    "\n",
    "Adds positional information to the embeddings.\n",
    "\n",
    "- Uses sine and cosine functions at different frequencies.\n",
    "\n",
    "```python\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        ...\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb171eaa",
   "metadata": {},
   "source": [
    "### TemporalEmbedding\n",
    "\n",
    "Encodes temporal features extracted from timestamps.\n",
    "\n",
    "- Embeds features like hour of the day, day of the week, month, etc.\n",
    "- Helps the model to capture seasonal patterns.\n",
    "\n",
    "\n",
    "```python\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        ...\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27825c0",
   "metadata": {},
   "source": [
    "### TimeFeatureEmbedding\n",
    "\n",
    "Alternative to *TemporalEmbedding*, uses a linear layer to embed time features.\n",
    "\n",
    "- Used when **embed_type** is set to 'timeF'.\n",
    "\n",
    "\n",
    "```python\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        ...\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587642d7",
   "metadata": {},
   "source": [
    "## 7. Projection Layer\n",
    "\n",
    "Maps the decoder output to the output dimensions (e.g., the number of features to predict).\n",
    "\n",
    " - Applies a linear transformation to produce the final output.\n",
    "\n",
    "```python\n",
    "self.projection = nn.Linear(d_model, c_out, bias=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e63bd07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "141ba8c0",
   "metadata": {},
   "source": [
    "# Data Flow through the model\n",
    "\n",
    "\n",
    "1. Input Preparation:\n",
    "   - x_enc: Encoder input sequence ( dcm rate data).\n",
    "   - x_mark_enc: Temporal features for the encoder input.\n",
    "   - x_dec: Decoder input sequence (e.g., placeholder for future values).\n",
    "   - x_mark_dec: Temporal features for the decoder input.\n",
    "\n",
    "1. Embedding:\n",
    "   - The inputs are passed through the DataEmbedding layer to generate embeddings.\n",
    "\n",
    "1. Encoding:\n",
    "   - The encoder processes the embeddings to capture temporal dependencies.\n",
    "\n",
    "1. Decoding:\n",
    "   - The decoder uses the encoder output and its own inputs to generate predictions.\n",
    "\n",
    "1. Projection:\n",
    "   - The decoder output is passed through the projection layer to obtain the final output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43508ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900cdbf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c686c32b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "985225cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd04fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
